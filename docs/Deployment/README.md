# Model Deployment Guide

Welcome to the Model Deployment section of AI Engineering Academy! This module will guide you through the practical aspects of deploying AI models in production environments.

### [LLM to Prod](./DeployLLMtoProd.md)

A blog on how to deploy open source LLMs into Produciton covering TGI,Vllm,SGlang

### Quantization Techniques

| Notebook                                                        | Description                                         |
| --------------------------------------------------------------- | --------------------------------------------------- |
| [**AWQ Quantization**](./Quantization/AWQ_Quantization.ipynb)   | Activation-aware Weight Quantization implementation |
| [**GGUF Quantization**](./Quantization/GGUF_Quantization.ipynb) | GGUF format quantization guide                      |

## ü§ù Contributing

Interested in contributing to this section? We welcome:

- Additional deployment strategies
- Case studies
- Performance optimization techniques
- Best practices documentation

See our contributing guidelines for more information.

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

<div align="center">
  Coming Soon: Complete deployment guides for production AI systems!
  <br>
  Made with ‚ù§Ô∏è by the AI Engineering Academy Team
</div>
